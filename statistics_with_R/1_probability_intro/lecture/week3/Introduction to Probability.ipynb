{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-30 at 5.16.48 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/07vL4/introduction) 1:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examples of random processes are coin tosses, die rolls, the shuffle mode on your music player, or the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A traditional definition of probability is a relative frequency. This is the **frequentist interpretation** of probability, where the probability of an outcome is the proportion of the times the outcome would occur if we observed the random process an infinite number of times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An alternative interpretation is the **Bayesian interpretation**. A Bayesian interprets a probability as a subjective degree of belief. For the same event, two separate people could have different viewpoints and so assign different probabilities to it. This interpretation allows for prior information to be integrated into the inferential framework. Bayesian methods have been largely popularized by revolutionary advances in computational technology and methods during the last 20 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-30 at 5.20.11 PM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/07vL4/introduction) 2:40*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## law of large numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The law of large numbers states that as more observations are collected, the proportion of occurrences with a particular outcome converges to the probability of that outcome. \n",
    "- This is why, as we roll a fair die many times, we expect the proportion of say, fives, to settle down to one-sixth. While earlier in the sequence, with too few rolls, we might not exactly get one in six fives. For example, if you roll a die say, six times, there's no guarantee that you're going to get at least one five in there. But if you roll the die say, 600 or 6,000 times, you would expect to see about one-sixth of the time to get a five. Similarly, why it would be more surprising to see three heads in 1,000 coin flips, than three heads in 10 or 100 coin flips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/Screen Shot 2016-05-31 at 8.55.11 AM.png\">\n",
    "<img src=\"images/Screen Shot 2016-05-31 at 8.55.33 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/07vL4/introduction) 3:40*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Say you toss a coin ten times, and it lands on heads each time. What do you think the chance is that another head will come up on the next toss? 0.5, less than 0.5, or more than 0.5? \n",
    "- The probability is still 50%. So, the probability of heads on the11th toss is the same as the probability of heads on the 10th toss, or any previous tosses, which is 0.5. Each toss is independent, hence, the outcome of the next toss does not depend on the outcome of the previous toss. Another way of thinking about it is that the coin is memoryless. It doesn't remember what happened before and say to itself, well let me roll over on the other side next time. In other words, the coin is not due for a tail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Screen Shot 2016-05-31 at 9.04.55 AM.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/probability-intro/lecture/07vL4/introduction) 4:46*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disjoint Events + General Addition Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "8",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
